Version 1:
We took the HeuristicAgent as a basis to develop our own, additionally the forward model was copied to allow changes.
Improvements we made are:
* The node construction was sped up by calling prune less often. This was achieved by explicitly excluding illegal moves from being considered.
* Pruning also was improved by not checking legality of actions multiple times.
* Value function: The type of collected item is considered to not collect a Kick when the agent already has this ability.
* Value function: Only own bombs are looked at when calculating how many clouds can be destroyed, additionally the bomb range is taken into account.
* Value function: when there are little clouds remaining, or the agent has collected all possible upgrades, it goes into "attack mode".
* Value function: In attack mode, the agent prioritises going towards the other agent, and placing bombs if the other agent is in range.
* Forward model: Flame ticks are modeled correctly, ammo is tracked.

NEW CHANGES:
Version 2:
* Value function: Bomb life is considered so that bombs are placed rather sooner than later.
* Value function: If the agent is locked in AND there is a bomb that cannot be kicked, it is considered certain death
* Value function: Adjusted scores.
* Node: Very inefficient code was cut to double the number of rollouts.
* Observations: Correct enemy modeling.
* Increased depth.
Is it better?
As it can still put out the same amount of rollouts although it has a larger search depth, we assume it will perform better as all other changes made it more complicated and take more information into account. When run on our laptops, it played noticeably better in most arenas.

Version 3:
* Value function: now using A* Algorithm to calculate closeness to enemy agent, instead of manhattan distance, because that caused it to run into walls
* Value function: Normalised Scoring function output for the interval of 0 to 1
* Value function: Adjusted bomb scoring to take bomb age into account
* MCTS: Depth is decreased from 7 to 6 because of the usage of A*
* MCTS: Tree is reused: The own move is stored and the enemy's move is calculated.
    If a matching child node exists and it is deterministic (no items were spawned), the root node is set to this child.
    If the enemy is not modeled (action = STOP), the tree is still reused if the enemy made the STOP action.
Is it better?
Compared to last time, the agent is more efficient and less indecisive when farming due to the normalized scoring.
Also, in the endgame, when both agents are close, the tree is reused very often, leading to more efficient search.